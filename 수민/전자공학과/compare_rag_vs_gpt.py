import os
import getpass
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.llms import OpenAI
from langchain.chains import RetrievalQA

# ğŸ” OpenAI API Key ì…ë ¥ ë°›ê¸°
api_key = getpass.getpass("ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
os.environ["OPENAI_API_KEY"] = api_key

# 1. RAG ì²´ì¸ (ë¬¸ì„œ ê¸°ë°˜ GPT)
embedding = OpenAIEmbeddings(openai_api_key=api_key)
vectordb = Chroma(persist_directory="./db", embedding_function=embedding)
llm_rag = OpenAI(openai_api_key=api_key, temperature=0)
rag_chain = RetrievalQA.from_chain_type(
    llm=llm_rag,
    retriever=vectordb.as_retriever(),
    chain_type="stuff"
)

# 2. GPT ë‹¨ë… (ë¬¸ì„œ ê¸°ë°˜ X)
llm_gpt = OpenAI(openai_api_key=api_key, temperature=0)

# 3. ì§ˆë¬¸ ì…ë ¥
question = "2025ë…„ 3ì›” í•™ì‚¬ì¼ì •í‘œ ë‚´ìš© ë° ì¼ì •ì— ëŒ€í•´ ì•Œë ¤ì¤˜"

# 4. RAG ë‹µë³€
rag_answer = rag_chain.run(question)

# 5. GPT ë‹¨ë… ë‹µë³€
gpt_answer = llm_gpt.invoke(question).strip()

# 6. ê²°ê³¼ ì¶œë ¥
print("ğŸ§ª ì§ˆë¬¸:", question)
print("\nâœ… [RAG ê¸°ë°˜ ì‘ë‹µ]")
print(rag_answer)
print("\nâŒ [Open AI ë‹¨ë… ì‘ë‹µ]")
print(gpt_answer)
