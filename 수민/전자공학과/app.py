# app.py

import streamlit as st
import os
import getpass
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.llms import OpenAI
from langchain.chains import RetrievalQA

# ğŸ” OpenAI API Key ì…ë ¥ ë°›ê¸°
openai_api_key = getpass.getpass("ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
os.environ["OPENAI_API_KEY"] = openai_api_key

# ë²¡í„° DB ë¶ˆëŸ¬ì˜¤ê¸°
embedding = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectordb = Chroma(persist_directory="./db", embedding_function=embedding)

# LLM ì¤€ë¹„
llm = OpenAI(openai_api_key=openai_api_key, temperature=0)

# RAG QA ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectordb.as_retriever(),
    chain_type="stuff"
)


# Streamlit UI êµ¬ì„±
st.set_page_config(page_title="ì „ìê³µí•™ê³¼ AI ë¹„ì„œ", page_icon="ğŸ¤–")
st.title("ğŸ“˜ ì „ìê³µí•™ê³¼ í•™ì‚¬ ì •ë³´ ì±—ë´‡")

question = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?", placeholder="ì˜ˆ: ì¡¸ì—… í•™ì ì€ ëª‡ ì ì¸ê°€ìš”?")

if question:
    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        answer = qa_chain.run(question)
    st.success("ğŸ’¬ ë‹µë³€:")
    st.write(answer)
