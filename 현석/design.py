import os
import streamlit as st
from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_anthropic import ChatAnthropic

# ğŸ” Claude API Key ë¡œë“œ
load_dotenv()
os.environ["ANTHROPIC_API_KEY"] = os.getenv("CLAUDE_API_KEY")

# ğŸŒ Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ“˜ ê²½ë¶ëŒ€ ì±—ë´‡", layout="centered")

# ğŸ« ìƒë‹¨ ë¡œê³  & íƒ€ì´í‹€
col1, col2 = st.columns([1, 5])
with col1:
    st.image("assets/knu_logo.png", width=70)
with col2:
    st.markdown("<h2 style='margin-top:18px;'>ğŸ“˜ ê²½ë¶ëŒ€í•™êµ AI ë„ìš°ë¯¸</h2>", unsafe_allow_html=True)


# ğŸ“ PDF í´ë” ë‚´ ë¬¸ì„œ í†µí•© ì²˜ë¦¬
PDF_DIR = "./data"
pdf_files = [f for f in os.listdir(PDF_DIR) if f.endswith(".pdf")]

if not pdf_files:
    st.error("âŒ data í´ë”ì— PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

@st.cache_resource
def build_combined_rag(pdf_dir):
    all_docs = []
    for filename in os.listdir(pdf_dir):
        if filename.endswith(".pdf"):
            path = os.path.join(pdf_dir, filename)
            loader = PyPDFLoader(path)
            pages = loader.load_and_split()
            for p in pages:
                p.metadata["source"] = filename
            all_docs.extend(pages)

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    docs = splitter.split_documents(all_docs)

    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectorstore = Chroma.from_documents(docs, embedding=embeddings)
    retriever = vectorstore.as_retriever()

    llm = ChatAnthropic(model="claude-3-haiku-20240307")

    system_prompt = """ë‹¹ì‹ ì€ ê²½ë¶ëŒ€í•™êµ í•™ì‚¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ì¤‘í•œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ëŠ” AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤. \
ê°€ì¥ ê´€ë ¨ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•´ì£¼ì„¸ìš”.\n{context}"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])

    chain = (
        {"context": retriever | (lambda d: "\n\n".join(doc.page_content for doc in d)), "input": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain

# âœ… ì²´ì¸ ì´ˆê¸°í™”
chain = build_combined_rag(PDF_DIR)

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ğŸ“˜ ê²½ë¶ëŒ€ í•™ì‚¬ ê´€ë ¨ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš” :)"}
    ]

# âœ… ëŒ€í™” ë Œë”ë§ (ë§ˆìŠ¤ì½”íŠ¸ + ë§í’ì„ )
for msg in st.session_state["messages"]:
    if msg["role"] == "assistant":
        col1, col2 = st.columns([1, 5])
        with col1:
            st.image("assets/mascot.png", width=90)
        with col2:
            st.markdown(f"""
                <div style='background-color:#f0f2f6; padding:15px 20px; 
                            border-radius:15px; margin-bottom:15px;
                            border: 1px solid #ccc; box-shadow: 2px 2px 4px rgba(0,0,0,0.1);'>
                    {msg['content']}
                </div>
            """, unsafe_allow_html=True)

    elif msg["role"] == "user":
        st.markdown(f"<p style='text-align:right; color:#dcdcdc;'>ğŸ™‹â€â™‚ï¸ {msg['content']}</p>", unsafe_allow_html=True)

# âœ… ì‚¬ìš©ì ì…ë ¥
if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: íœ´í•™ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?)"):
    st.session_state["messages"].append({"role": "user", "content": query})
    st.markdown(f"<p style='text-align:right; color:#dcdcdc;'>ğŸ™‹â€â™‚ï¸ {query}</p>", unsafe_allow_html=True)

    with st.spinner("Claudeê°€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ìˆì–´ìš”..."):
        try:
            answer = chain.invoke(query)
            st.session_state["messages"].append({"role": "assistant", "content": answer})
        except Exception as e:
            st.session_state["messages"].append({"role": "assistant", "content": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"})
