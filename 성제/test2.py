# ğŸ§  1. ê¸°ë³¸ ëª¨ë“ˆ ë° API í‚¤ ì„¤ì •
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_anthropic import ChatAnthropic
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain.schema.runnable import RunnableLambda, RunnablePassthrough
import os
import getpass


# ğŸ” Claude API Key ì…ë ¥ ë°›ê¸°
claude_api_key = getpass.getpass("Claude API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
os.environ["ANTHROPIC_API_KEY"] = claude_api_key

# ğŸ“ 2. PDF ë¡œë”© (ê²½ë¶ëŒ€ PDF í´ë” ê²½ë¡œ)
folder_path = "C:/Users/KDT10/OneDrive/ë°”íƒ• í™”ë©´/ê²½ë¶ëŒ€í•™êµ"
loader = PyPDFDirectoryLoader(folder_path)
documents = loader.load()

# âœ… ë¶ˆëŸ¬ì˜¨ PDF ìˆ˜ í™•ì¸
print(f"ğŸ“„ ë¶ˆëŸ¬ì˜¨ PDF ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ")

# ğŸ“š 3. ì²­í¬ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)
chunks = text_splitter.split_documents(documents)
print(f"ğŸ§© ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")

# ğŸ“Œ 4. ì„ë² ë”© ëª¨ë¸ (í•œêµ­ì–´ HuggingFace ëª¨ë¸ ì‚¬ìš©)
embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

# ğŸ§  5. ë²¡í„° ì €ì¥ì†Œ ìƒì„± (Chroma ì‚¬ìš©)
vectorstore = Chroma.from_documents(documents=chunks, embedding=embedding_model)
retriever = vectorstore.as_retriever()

# ğŸ¤– 6. Claude ê¸°ë°˜ LLM ì„¤ì •
llm = ChatAnthropic(model="claude-3-haiku-20240307")

# ğŸ”„ 7. RAG ì²´ì¸ êµ¬ì„±
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | RunnableLambda(lambda x: f"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n\n{x['context']}\n\nì§ˆë¬¸: {x['question']}")
    | llm
)

# ğŸ§ª 8. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
query = "ë°°ì¤€í˜„ êµìˆ˜ë‹˜ ì´ë©”ì¼ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
response = rag_chain.invoke(query)
print(f"\nğŸ“¢ ë‹µë³€:\n{response.content}")
