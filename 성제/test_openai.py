import os
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from bert_score import score as bert_score
from getpass import getpass

# âœ… 1. OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = getpass("ğŸ” OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")

# âœ… 2. ê²½ë¡œ ì„¤ì •
pdf_dir = r"C:\_vscode\Project_13\ì„±ì œ\ê²½ë¶ëŒ€í•™êµ"

# âœ… 3. ëª¨ë“  PDF íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
loaders = [PyPDFLoader(os.path.join(pdf_dir, f))
           for f in os.listdir(pdf_dir) if f.endswith(".pdf")]
print(f"ğŸ“„ ë¶ˆëŸ¬ì˜¨ PDF íŒŒì¼ ìˆ˜: {len(loaders)}")

# âœ… 4. ë¬¸ì„œ ë¡œë“œ + ì²­í¬í™”
docs = []
for loader in loaders:
    docs.extend(loader.load())
print(f"ğŸ“ƒ ì „ì²´ ë¬¸ì„œ í˜ì´ì§€ ìˆ˜: {len(docs)}")

splitter = RecursiveCharacterTextSplitter(
    chunk_size=700, chunk_overlap=100,
    separators=["\n\n", "\n", " ", ""]
)
chunks = splitter.split_documents(docs)
print(f"ğŸ§© ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")

# âœ… 5. ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vectorstore = Chroma.from_documents(
    chunks,
    embedding=OpenAIEmbeddings(model="text-embedding-3-small"),
    persist_directory="./knu_vectorstore"
)
vectorstore.persist()
print("âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!")

# âœ… 6. ì§ˆì˜ì‘ë‹µ ì²´ì¸ êµ¬ì„±
retriever = vectorstore.as_retriever()
rag_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    retriever=retriever
)
gpt_direct = ChatOpenAI(model="gpt-3.5-turbo")

# âœ… 7. ë¹„êµ ë£¨í”„ ì‹œì‘
while True:
    query = input("\nğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if query.lower() == "exit":
        break

    print("ğŸ¤– RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„± ì¤‘...")
    rag_answer = rag_chain.run(query)

    print("ğŸ¤– ì¼ë°˜ GPT ì‘ë‹µ ìƒì„± ì¤‘...")
    gpt_answer = gpt_direct.predict(query)

    print("\nâœ… [RAG ì‘ë‹µ]:\n", rag_answer)
    print("\nâœ… [GPT ë‹¨ë… ì‘ë‹µ]:\n", gpt_answer)

    # âœ… BERT-Score ê³„ì‚°
    P, R, F1 = bert_score(
        [rag_answer],  # candidate
        [gpt_answer],  # reference
        lang="ko",     # í•œêµ­ì–´ì¼ ê²½ìš°
        model_type="xlm-roberta-large"  # í•œêµ­ì–´ ì§€ì› ëª¨ë¸
    )

    print(f"\nğŸ“Š BERT-Score ìœ ì‚¬ë„")
    print(f"Precision: {P.mean():.4f}")
    print(f"Recall   : {R.mean():.4f}")
    print(f"F1       : {F1.mean():.4f}")
