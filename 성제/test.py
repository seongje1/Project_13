import os
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from getpass import getpass

# âœ… 1. OpenAI API í‚¤ ì„¤ì •
import os
os.environ["OPENAI_API_KEY"] = "your-openai-key"

# âœ… 2. ê²½ë¡œ ì„¤ì •
pdf_dir = r"C:\Users\KDT10\OneDrive\ë°”íƒ• í™”ë©´\ê²½ë¶ëŒ€í•™êµ"

# âœ… 3. ëª¨ë“  PDF íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
loaders = []
for filename in os.listdir(pdf_dir):
    if filename.endswith(".pdf"):
        file_path = os.path.join(pdf_dir, filename)
        loaders.append(PyPDFLoader(file_path))

print(f"ğŸ“„ ë¶ˆëŸ¬ì˜¨ PDF íŒŒì¼ ìˆ˜: {len(loaders)}")

# âœ… 4. ë¬¸ì„œ ë¡œë“œ + ì²­í¬í™”
docs = []
for loader in loaders:
    docs.extend(loader.load())

print(f"ğŸ“ƒ ì „ì²´ ë¬¸ì„œ í˜ì´ì§€ ìˆ˜: {len(docs)}")

# âœ… 5. ì²­í¬ ë‚˜ëˆ„ê¸°
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", " ", ""]
)
chunks = splitter.split_documents(docs)

print(f"ğŸ§© ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")

# âœ… ì²­í¬ ë‚´ìš© ì¼ë¶€ ì¶œë ¥ (ìƒìœ„ 3ê°œë§Œ ì˜ˆì‹œ)
for i, chunk in enumerate(chunks[:30]):
    print(f"\nğŸ§© ì²­í¬ {i+1}:\n{chunk.page_content[:]}")  # ì²˜ìŒ 500ìê¹Œì§€ë§Œ ì¶œë ¥

# âœ… 6. ë²¡í„° ì €ì¥ì†Œ ìƒì„±
vectorstore = Chroma.from_documents(
    chunks,
    embedding=OpenAIEmbeddings(model="text-embedding-3-small"),
    persist_directory="./knu_vectorstore"  # ë¡œì»¬ì— ì €ì¥
)

vectorstore.persist()
print("âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!")

# âœ… 7. ì§ˆì˜ì‘ë‹µ ì²´ì¸ êµ¬ì„±
retriever = vectorstore.as_retriever()
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model="gpt-3.5-turbo"),
    retriever=retriever
)

# âœ… 8. ì§ˆë¬¸ ì˜ˆì‹œ
while True:
    query = input("\nğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit'): ")
    if query.lower() == "exit":
        break
    answer = qa_chain.run(query)
    print("ğŸ¤– ë‹µë³€:", answer)
